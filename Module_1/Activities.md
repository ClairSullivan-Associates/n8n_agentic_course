# Module 1 Activities: Foundational Agentic Patterns

In this module we will learn the basics of how to use n8n for basic agentic workflows.  At this point, you should be able to log into n8n.  We will start with a basic chatbot and work on building it out to add more complexity.

## Module 1, Activity 1: Basic Chatbot

We will begin by creating our first workflow.  From the n8n dashboard, click on your Peronsal workspace.  Then click on "New Workflow" in the upper right corner.  This will open a blank workflow.  

![](./pics/new_workflow.jpg)

The first thing to know is that all n8n workflows start with a trigger node.  This is the node that tells n8n when to start the workflow.  For many workflows, we will use the "Manual Trigger" node.  This allows us to manually start the workflow by clicking a button.  However, our first workflow in this course will be a chatbot, so we want to use a chat trigger.  Click the "+" button in the upper right to open the Nodes Panel.  In the node search bar, type "chat" and select the "Chat Trigger" node.

![](./pics/chat_trigger.jpg)

At this point we do not need to adjust any of the parameters or settings for this node so we can return back to the canvas.  Observe in the lower left a chat window has been opened.  It isn't connected to anything (yet!) so it won't do anything, but this is where we will interact with our chatbot.

Now we need to connect our chatbot to an AI.  We will be using the n8n AI Agent for this course.  Click the "+" button again to open the Nodes Panel.  In the search bar, type "AI Agent" and select the "AI Agent" node.  This will then open the AI Agent node, where you will see the following:

![](./pics/ai_agent.jpg)

There are a couple of key things to notice for this node.  First, we can see that the source for the prompt (AKA the user message) is "Connected Chat Trigger Node."  In fact, if you return to the canvas, you will see that the chat trigger node has been connected to the AI agent node.  This means that the agent is waiting for input from the chat window.  Later in this workshop we will not be running our agents based on chat but more sophisticated workflows.  But for this exercise, this is what we want.  Next you will see that the prompt (user message) is set to `{{ $json.chatInput }}`.  We will see in just a second that when we enter a message in the chat window, it will be stored in the variable `chatInput`.  This is how the AI agent node knows what the user said.  

Notice that there is a red asterisk below the AI Agent node next to "Chat Model."  This indicates that this is a required field.  ("Memory" and "Tool" are not required and we will discuss them shortly.)  This means that we need to hook our agent up to a large language model (LLM) to power our chat.  If you click on the "+" symbol there you will see a variety of options for chat models.  In this course, we will largely work with the Google Gemini Chat Model.  So select that model, which will bring up the following screen:

**ADD SECTION ABOUT GETTING CREDENTIALS FOR IT HERE**

![](./pics/gemini_chat_model.jpg)

### Saving Your Work

Note that n8n does not automatically save your work.  So it is important to periodically save your workflow as you are working on it.  To do this, click on the "Save" button in the upper right corner.  Should you wish to leave this workflow, n8n will prompt you to save your work before you exit.  But it is a good habit to save your work frequently.

### Testing Your Chatbot

We are now ready to try it out!  So enter into the chat window "what can you do?"  You should see an output that looks something like this:

![](./pics/first_output.jpg)

There is a lot going on here, so let's dissect it!  First, right when he hit "Enter/Return" you can see n8n in action in the workflow.  You will see the nodes turn from outlined in gray to outlined in green and receive a green check mark upon completion.  Nodes that are running are visually indicated by a spinning circles over the node.  Hopefully you don't see any nodes turn red, which indicates an error.  Also notice that the workflow tells you how many times each node has run.  In this case, we nee that the chat was received once and the model ran once.

Next, we can see that in the chat window we had returned to us the output of the agent in a nice format, as we would expect.  If you look to the right, we can see important information to the agent, such as the input and the output.  Notice that the input has a few variables.  We see that it has `chatInput`, as we expected from above, which was the thing we asked it.  We can also see that a `sessionId` variable was created.  This is a unique identifier that is used throughout agentic workflows, so it is important to see that it was generated by the chat trigger node.  Finally, we can see the output, which is the response from the AI model.

Now, let's try to ask it "what did I just ask you?"  If you do that, it will likely just repeat the question back to you, having forgotten that you had asked it what it could do before.  This is because the agent has no memory of past interactions yet.  As you likely have guessed, this is what the "Memory" section of the AI Agent node is for.  Click on the "+" symbol next to "Memory" to add memory to the agent.  For this exercise, select "Simple Memory."  This will allow the agent to remember past interactions in the current session.  When we do that, we will see the following:

![](./pics/simple_memory.jpg)

Notice that the memory node requires the `sessionId` variable that we saw earlier.  This is how the memory node knows which session to pull memory from.  Also notice that there is an entry for content length, which defaults to 5.  We can see that this variable name is green, meaning n8n successfully pulled in a value for this variable (shown just below that text) that it though was viable.  This means that the memory is set to remember up to 5 interactions ago (although you can set it to whatever you want within the memory limitations of the n8n cloud environment).  Now, if you return to the chat window, tell it your name, and then ask it "what is my name?"  You should see that it is now able to remember your name from the prior interaction!  Be sure to click on the memory node so you can see what all is being saved there.

We now have a fully-functional chatbot!  Let's start tweaking it a bit through updating the prompts.  Recall from lecture that we have both system prompts and user prompts (n8n calls the prompts "messages").  With what we have right now, we have just dumped whatever you said to the chatbot into the user prompt, which tells the LLM what question you want answered.  However, we might also want to specify some generic behavioral information that we always want the chatbot to always follow.  This is exactly the type of information you want to appear in a system prompt.  To access the system prompt, click on "Options" at the bottom of the AI Agent node and select "System Message."  This will open a text box where you can enter the system prompt.  n8n defaults to a system message of "You are a helpful assistant."  However, let's now change that, as shown below, to "Resond to all things in pirate speak."  Now give it a try in the chat window and observe the results!

We have just completed our first chatbot!  We are now going to work on expanding this chatbot into a more complex workflows in the next activities.

## Module 1, Activity 2: Routing Results to Places Other Than Chat

In the previous activity we created a basic chatbot that interacted with us through the chat window.  However, in many cases we will want to route the results of our agentic workflows to other places.  In this activity we will learn how to do that.

We are going to start with our chatbot from the prior activity.  At this stage, it should look like this:

![](./pics/basic_chatbot.jpg)

When you look at this workflow, you might notice that plus sign off to the right of the image.  This implies that it is possible to route the output of the agent somewhere other than just back into chat.  In this activity, we are going to do just that.  Our goal is going to create a basic sentiment classifer where the chat agent will take the user's input and then will attempt to determine whether what they said is happy or unhappy.  We will then route that information to a Google Sheet.

For the sake of this activity, let's use the following for our system prompt:

```
You are a helpful assistant.

After responding to the user, on a new line, add a sentiment classification in the format: 
SENTIMENT: [happy/unhappy]
   
Classify as "happy" if the user seems satisfied, positive, neutral, or content.  Classify as "unhappy" if the user seems frustrated, negative, or dissatisfied.
```

So basically, this is telling the agent to take its response and append `SENTIMENT` to the end of it along with the word `happy` or `unhappy` based on the sentiment of the user's input.  This type of approach makes it very easy for downstream nodes to parse the output and take action based on it.  Give it a try with some happy and unhappy inputs to see how it works.

So next, we want to use some `if/then` logic to say something like "if the sentiment is happy, do this, else do that."  To do this, we will use a "Switch" node.  Click on the plus sign to the right of the AI Agent node to add a new node.  In the Nodes Panel, search for "Switch" and select the "Switch" node.  This will open the Switch node, where you will see the following:

![](./pics/switch.jpg)

We now need to create our routing rules for the switch.  We know we are going to have two of them: one for happy and one for unhappy.  We also know that the output of the AI Agent node, `$json.output`, should contain `SENTIMENT: happy` or `SENTIMENT: unhappy`.  So we can use that to create our rules as we see here:

![](./pics/populated_switch.jpg)

Now is a good time to check out that button in the upper right of the node that says "Execute step."  This button allows us to run just this node in isolation, using the output of the prior node as input.  So click that button now to see how the switch is working.  You should see that it successfully routes the output to the correct branch based on the sentiment.  If you gave it a happy input in your last chat, you should see that Output 0 was selected (assuming you used the same order of routing rules as shown above).  If you gave it an unhappy input, you should see that Output 1 was selected.

Now let's get those results in real time somewhere that someone could look at them.  We are going to route the results to a Google Sheet for logging purposes.  Start by creating a Google Sheet called "sentiment" with the following columns:

- Timestamp
- Message
- Sentiment

Next we need to add some Google Sheet nodes to each output of the Swtich node.  Click on Output 0 of the Switch node to add a new node.  In the Nodes Panel, search for "Google Sheets" and select the "Google Sheets" node.  You will notice that you are then asked to select one of several different actions:

![](./pics/google_sheet_actions.jpg)

Here, we are going to add a new line to the sheet every time we get a new chat.  So select "Append Row."  This will open the Google Sheets node.  You will use your Google Sheets account as the credential and select "Sheet Within Document" as the resource.  Your operation is "Append Row."  From here, the node will give you drop downs to start filling out to identify which Google Sheet you are editing and which sheet within the spreadsheet you are appending to (just Sheet 1 for us, unless you named the tab something else).  From here, n8n will attempt to manually map each column, which is very helpful because you can just drag and drop the variables you want into each column.  We will use `$now` as the timestamp (i.e. when the chat was sent) and `output` as the Message.  Notice that you can drag these from the input variables to the node on the left.  Finally, we will use a global value for Sentiment.  Since we are starting with Output 0 of the Switch node, we know that the sentiment is happy.  So we can just type in "happy" for that column.  Your completed node should look something like this:

![](./pics/append_happy.jpg)

Now repeat this process for Output 1 of the Switch node, except this time set the Sentiment column to "unhappy."  

At this point, you have two different append row nodes in your workflow.  While this might not be too confusing with only two of them, note that you can rename nodes in n8n to make it easier to identify them.  To do so, click into the node and double click on the name at the top.  Change the names of your two Google Sheets nodes to something unique so you can easily identify them.  Here is what the completed workflow should look like:

![](./pics/sentiment_workflow.jpg)

Save your workflow and give it a try!  Enter some happy and unhappy messages into the chat window and then check your Google Sheet to see if the results were logged correctly.  If everything worked, you should see one row in the sheet for each chat you sent, along with the correct sentiment. 







